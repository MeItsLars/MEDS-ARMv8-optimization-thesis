\documentclass[11pt,a4paper]{report}

\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{algpseudocode}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{dsfont}
\usepackage{enumitem}
\usepackage[a4paper]{geometry}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{natbib}
\usepackage{parskip}
\usepackage{pgf-pie}
\usepackage{tabularx}
\usepackage{todonotes}
\usepackage{url}
\usepackage{xcolor}
\usepackage{xurl}

% Define nice pie chart colors
\definecolor{pie1}{HTML}{03045e}
\definecolor{pie2}{HTML}{023e8a}
\definecolor{pie3}{HTML}{0077b6}
\definecolor{pie4}{HTML}{0096c7}
\definecolor{pie5}{HTML}{00b4d8}
\definecolor{pie6}{HTML}{48cae4}
\definecolor{pie7}{HTML}{90e0ef}
\definecolor{pie8}{HTML}{ade8f4}
\definecolor{pie9}{HTML}{caf0f8}

\setlength{\marginparwidth}{2cm}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\lstdefinestyle{CStyle}{
  language=C,
  commentstyle=\color{green!60!blue},
  keywordstyle=\color{blue},
  numberstyle=\tiny\color{black!80},
  stringstyle=\color{green},
  basicstyle=\footnotesize\ttfamily,
  breakatwhitespace=false,         
  breaklines=true,                 
  captionpos=b,                    
  keepspaces=true,                 
  numbers=left,                    
  numbersep=5pt,                  
  showspaces=false,                
  showstringspaces=false,
  showtabs=false,                  
  tabsize=2,
  morekeywords={uint16x4_t, uint32x4_t, uint64x2_t, vmull_u32, vget_low_u32, vmull_high_u32, vuzp2q_u32, vshrq_n_u32, vmlsq_u32, vmovn_u32}
}


\lstdefinestyle{ASMStyle}{
  language=C,
  commentstyle=\color{green!60!blue},
  keywordstyle=\color{blue},
  numberstyle=\tiny\color{black!80},
  stringstyle=\color{green},
  basicstyle=\footnotesize\ttfamily,
  breakatwhitespace=false,         
  breaklines=true,                 
  captionpos=b,                    
  keepspaces=true,                 
  numbers=left,                    
  numbersep=5pt,                  
  showspaces=false,                
  showstringspaces=false,
  showtabs=false,                  
  tabsize=2,
  morekeywords={umull, umull2, uzp2, ushr, mls, xtn}
}

% Set the line spacing between paragraphs
% \setlength{\parskip}{1em}
% Remove paragraph indentation
% \setlength{\parindent}{0pt}

% URL LINE BREAKS
\expandafter\def\expandafter\UrlBreaks\expandafter{\UrlBreaks% save the current one
  \do\a\do\b\do\c\do\d\do\e\do\f\do\g\do\h\do\i\do\j%
  \do\k\do\l\do\m\do\n\do\o\do\p\do\q\do\r\do\s\do\t%
  \do\u\do\v\do\w\do\x\do\y\do\z\do\A\do\B\do\C\do\D%
  \do\E\do\F\do\G\do\H\do\I\do\J\do\K\do\L\do\M\do\N%
  \do\O\do\P\do\Q\do\R\do\S\do\T\do\U\do\V\do\W\do\X%
  \do\Y\do\Z\do\*\do\-\do\~\do\'\do\"\do\-}%

\makeatletter %otherwise geometry resets everything
\Gm@restore@org
\makeatother

\setlength{\itemsep}{0cm}
\setlength{\voffset}{0cm}
\setlength{\headheight}{0cm}
\setlength{\topmargin}{0cm}

\graphicspath{{imgs/}}

\begin{document}
\begin{titlepage}
  \begin{center}
    \textsc{\LARGE Master Thesis\\Computing Science}\\[1.5cm]
    \includegraphics[height=100pt]{logo}

    \vspace{0.4cm}
    \textsc{\Large Radboud University}\\[1cm]
    \hrule
    \vspace{0.4cm}
    \textbf{\huge Optimizing MEDS implementation for ARMv8}\\[0.4cm]
    \vspace{0.2cm}
    \hrule
    \vspace{2cm}
    \begin{minipage}[t]{0.45\textwidth}
      \begin{flushleft} \large
        \textit{Author:}\\
        Lars Jeurissen\\
        s1022856\\
        \texttt{lars.jeurissen@ru.nl}
      \end{flushleft}
    \end{minipage}
    \begin{minipage}[t]{0.45\textwidth}
      \begin{flushright} \large
        \textit{First supervisor/assessor:}\\
        prof. dr. Peter Schwabe\\
        \texttt{p.schwabe@cs.ru.nl}\\[1.3cm]
        \textit{Second supervisor:}\\
        dr. Simona Samardjiska\\
        \texttt{simonas@cs.ru.nl}
      \end{flushright}
    \end{minipage}
    \vfill
    {\large \today}
  \end{center}
\end{titlepage}

\input{acknowledgements.tex}

\input{abstract.tex}

\tableofcontents
\newpage

\chapter{Introduction}
\label{ch:introduction}
\todo[inline]{Cite Shor and Grover}
As the research on quantum computers progresses, we are getting increasingly closer to the point where quantum computers will be able to utilize algorithms such as Shor's algorithm and Grover's algorithm to break a lot of symmetric and asymmetric cryptographic schemes. As the majority of the internet's security relies on these cryptographic schemes, the consequences of this are severe. Without proper measurements, quantum computers will cause the absolute collapse of the present public key algorithms that are considered secure \cite{mavroeidis2018impact}, wich would have devestating consequences for the security of the internet.

The solution to this problem lies in the development of cryptographic schemes that are secure against quantum computers. Such algorithms have been around for a long time, but this area of research has experienced a boost in attention ever since the National Institute of Standards and Technology (NIST) started the post-quantum cryptography (PQC) standardization process in 2017 \cite{nist2017pqc}. The goal of this process is to standardize cryptographic schemes that are secure against quantum computers.

In 2022, NIST announced the set of selected PQC algorithms. Unfortunately, this set did not include any algorithms for digital signatures. To address this, NIST announced a second competition in the PQC standardization process, which aims to find a set of secure digital signature schemes. One of the candidates in this competition is Matrix Equivalence Digital Signature (MEDS) \cite{chou2023take}. MEDS is a code-based digital signature scheme based on the notion of Matrix Code Equivalence.

Although the MEDS scheme is actively being optimized in terms of key and signature sizes, the performance of the scheme is still lacking. The reported signature verification times are in the order of hundreds of milliseconds, sometimes even seconds. \todo[inline]{In which section do we compare the performance of MEDS to the performance of other (similar) digital signature schemes?}

In this thesis, we aim to optimize the speed of the MEDS implementation. We will look at the general performance of MEDS, but we will mostly focus on the ARMv8 architecture. This architecture is used in a wide range of devices, including many mobile devices and tablets, Internet of Things (IoT) devices, and Apple M1/M2 chips. By optimizing the MEDS implementation for ARMv8, we aim to improve the MEDS performance for these devices, as well as obtain a better understanding of the performance of MEDS.

We investigate the following research questions in this thesis (see also Chapter \ref{ch:researchobjectives}):
\begin{itemize}
  \item What are the bottlenecks in the MEDS implementation?
  \item How can we improve the general performance of the MEDS implementation?
  \item How can we optimize the MEDS implementation for ARMv8?
  \item How does the optimized MEDS implementation compare to (optimized) implementations of other digital signature schemes?
\end{itemize}

In Chapter \ref{ch:background}, we will provide the necessary background information on the functioning of MEDS and the specific details of the ARMv8 architecture. In Chapter \ref{ch:researchobjectives}, we will discuss the research objectives of this thesis. In Chapter \ref{ch:profiling}, we discuss the profiling techniques that we use to obtain an understanding of the performance of MEDS. In this Chapter, we will also present the profiling results of the MEDS implementation. Following that, in Chapter \ref{ch:methodology}, we will discuss the optimization techniques that we use to optimize the MEDS implementation. In Chapter \ref{ch:results}, we will present the benchmarking results of the non-optimized and optimized MEDS versions and compare these results to other digital signature schemes. In Chapter \ref{ch:discussion}, we will discuss the results that we have obtained. Finally, in Chapter \ref{ch:futurework}, we will discuss the future work that can be done in this area. We will conclude the thesis in Chapter \ref{ch:conclusion}, where we will reflect on the research questions and the results that we have obtained.

\chapter{Background}
\label{ch:background}

\section{Matrix Equivalence Digital Signature (MEDS)}
\label{sec:meds}
Matrix Equivalence Digital Signature (MEDS) \cite{chou2023take} is a code-based digital signature scheme and the candidate in the NIST PQC competition that we aim to optimize in this thesis. A series of optimizations for the key and signature sizes of MEDS have already been proposed by the authors of the scheme in \cite{chou2024reducing}, together with a new reference implementation that implements these optimizations. In this paper, we will focus our efforts on optimizing this new reference implementation.

\subsection{Signature Schemes}
\label{sec:signatureschemes}
A digital signature scheme is a cryptographic scheme with the purpose of verifying the authenticity of a message. The scheme allows a party to sign a piece of data such as a message or a document, after which any party can verify the signature and thereby the authenticity of the data.

A digital signature scheme consists of three algorithms:
\begin{itemize}
  \item \textbf{Key generation}: This algorithm generates 2 keys, a private key and a public key. The private key is used to sign the data, and the public key is used to verify the signature.
  \item \textbf{Signature generation}: Given a message and the private (and sometimes public) key, this algorithm generates a signature for the message.
  \item \textbf{Signature verification}: Given a message, a signature, and the public key, this algorithm verifies the signature.
\end{itemize}

Formally, a digital signature scheme is defined as a tuple of algorithms $(\text{G}, \text{S}, \text{V})$ \cite{goldwasser2008lecture}, where:
\begin{itemize}
  \item $\text{G}(1^n)$ generates a key pair $(pk, sk)$, where $pk$ is the public key and $sk$ is the private key. The parameter $n$ represents the security parameter which determines the security level of the scheme.
  \item $\text{S}(sk, m)$ generates a tag $T$ which represents the signature of the message $m$ using the private key $sk$.
  \item $\text{V}(pk, m, T)$ outputs 1 if the tag $T$ is a valid signature of the message $m$ using the public key $pk$, and 0 otherwise.
\end{itemize}
Such that, given $(pk, sk) \leftarrow \text{G}(1^n)$:
\[
  \text{V}(pk, m, \text{S}(sk, m)) = 1
\]
for all $m$.

\subsection{How MEDS works}
\label{sec:medsworks}
Most PQC schemes are based on mathematical concepts such as linear codes, isogenies, lattices and multivariate equations. These concepts have associated decisional and computational problems that are believed to be hard to solve for both classical and quantum computers. MEDS is based on the notion of Matrix Code Equivalence, which is closely related to the notion of Code Equivalence that is used in LESS \cite{biasse2020less}, a similar scheme in the NIST PQC Signature competition.

\subsubsection{The Matrix Code Equivalence (MCE) Problem}
MEDS bases its security on the hardness of the Matrix Code Equivalence (MCE) problem. The computational form of this problem is defined as follows \cite{chou2023meds}:
\begin{center}
  \textbf{MCE Problem}\\
  Given two rank metric codes $\mathcal{C}, \mathcal{D}$ of size $[m \times n, k]$,\\
  find an isometry $\phi$ on $\mathbb{F}_q^{m \times n}$ such that $\mathcal{C} = \phi(\mathcal{D})$.
\end{center}
where an isometry $\phi$ is an $\mathbb{F}_q$-linear map that preserves the rank of matrices. For more information, we refer the reader to \cite{reijnders2024hardness}, where the problem is explained in more detail and its hardness is studied.

\subsubsection{Sigma Protocol}
\label{sec:sigmaprotocol}
The MCE problem is used in MEDS to construct a 3-pass Sigma protocol. A Sigma protocol is a protocol between a prover and a verifier where the prover convinces the verifier that it knows a piece of information without revealing the information itself. In the case of MEDS, the prover convinces the verifier that it knows a certain isometry $\phi$ that satisfies the MCE problem. The Sigma protocol for the optimized version of MEDS is provided in \cite{chou2024reducing}.
\todo[inline]{Indicate in which section the Sigma protocol is discussed.}

\subsubsection{Fiat-Shamir Transform}
\label{sec:fiatshamir}
To convert a Sigma protocol into a usable digital signature scheme, the Fiat-Shamir transform \cite{fiat1986prove} is used. This transform converts the Sigma protocol such that the prover can show knowledge of the isometry while only sending a single message to the verifier. This is achieved by creating the challenge based on a collision-resistant hash of the message to be signed and the commitments for each round.

In the Fiat-Shamir transform, various techniques and optimizations can be used to increase the security or lower the size of the public key and the signature. The following techniques are considered in the MEDS scheme:
\begin{itemize}
  \item \textbf{Multiple Challenges}: An attacker can impersonate an honest prover with $\frac{1}{2}$ probability. To prevent this, the scheme can use $t$ challenges, reducing the probability of impersonation to $\frac{1}{2^t}$.
  \item \textbf{Multiple Public Keys}: As mentioned before, an attacker can impersonate an honest prover with $\frac{1}{2}$ probability. To reduce this probability, the scheme can use multiple public keys, each of which is used to compute a different isometry. This increases the challenge space from $2$ to $s$, where $s$ is the number of public keys.
  \item \textbf{Fixed-Weight Challenge Strings}: If a challenge is 0, the response consists of matrices that are generated uniformly at random. In this case, it is sufficient to set the response to the seed that was used to generate the matrices, greatly reducing the size of the signature. By fixing a certain number $w$ of challenges to 0, the average size of a response can be reduced. This technique has a slightly negative impact on the security of the scheme, but this can be compensated by increasing the number of challenges.
  \item \textbf{Seed Tree}: If a scheme requires sending multiple seeds for the generation of matrices (or other objects), a seed tree can be used to reduce the size of the public key and the signature. This is a structure that allows the prover to transmit a smaller amount of bits than the size of the seeds, at the cost of an increased computational complexity.
\end{itemize}

By selecting $t$, $s$ and $w$ carefully and combining them with other parameters of the scheme, the security of the scheme can be increased to the desired level. Multiple combinations of parameters are used in MEDS to achieve various security levels \cite{chou2023meds}. The selection of these parameters has a big influence on the size of the public key and the signature, as well as the computational performance of the scheme.

\subsection{Parameter Sets}
\label{sec:parametersets}
The security of MEDS depends on the choice of a set of parameters. The parameters that are used in the MEDS scheme are the following:
\begin{itemize}
  \item $q$: The size of the finite field $\mathbb{F}_q$ over which all computations are done.
  \item $n$: The width and height of the private matrices $A_i \in \mathbb{F}_q^{n \times n}$ that are used to generate the key pair.
  \item $m$: The width and height of the private matrices $B_i \in \mathbb{F}_q^{m \times m}$ that are used to generate the key pair.
  \item $k$: The width and height of the private matrices $T_i \in \mathbb{F}_q^{k \times k}$ that are used to generate the key pair.
  \item $s$: The number of different public keys that are used in the scheme.
  \item $t$: The number of challenges that are used in the Fiat-Shamir transform.
  \item $w$: The number of challenges in the Fiat-Shamir transform that are fixed to be 0.
\end{itemize}

The team behind MEDS has proposed three parameter sets for the new optimized version of the scheme. These parameter sets are optimized for the three different security levels that are required in the NIST PQC competition. The parameter sets are shown in Table \ref{tab:medsparametersets}. The security level for each parameter set is shown in Table \ref{tab:medssecuritylevels}.

\begin{table}
  \centering
  \begin{tabular}{lccccccccc}
    \toprule
    \textbf{Parameter Set} & \textbf{$q$} & \textbf{$n$} & \textbf{$m$} & \textbf{$k$} & \textbf{$s$} & \textbf{$t$} & \textbf{$w$} & \textbf{pk} & \textbf{sig} \\
    \midrule
    MEDS-21595 & 4093 & 26 & 25 & 25 & 2 & 144 & 48 & 21595 & 5200 \\
    MEDS-55520 & 4093 & 35 & 34 & 34 & 2 & 208 & 75 & 55520 & 10906 \\
    MEDS-122000 & 4093 & 45 & 44 & 44 & 2 & 272 & 103 & 122000 & 19068 \\
    \bottomrule
  \end{tabular}
  \caption{MEDS Parameter Sets. \textbf{pk} and \textbf{sig} represent the size in bytes of the public key and the signature, respectively.}
  \label{tab:medsparametersets}
\end{table}

\begin{table}
  \centering
  \begin{tabular}{lcc}
    \toprule
    \textbf{Parameter Set} & \textbf{NIST Category} & \textbf{FS} \\
    \midrule
    MEDS-21595 & Level 1 & -128.406 \\
    MEDS-55520 & Level 3 & -192.058 \\
    MEDS-122000 & Level 5 & -256.005 \\
    \bottomrule
  \end{tabular}
  \caption{MEDS Security Levels. \textbf{FS} denotes the claimed security of a MEDS parameter set in bits.}
  \label{tab:medssecuritylevels}
\end{table}

We can see that all parameter sets use the same finite field size $q = 4093$. The dimensions of the matrices that are used increase with each security level, as well as the number of challenges $t$ (and the number of fixed challenges $w$). The number of public keys $s$ is always set to 2, meaning the scheme does not use the multiple public keys technique, which would have greatly increased the size of the public key and the signature. Note that this differs from the original MEDS scheme, which used multiple public keys \cite{chou2023meds}.

% A section that references the 3 meds algorithms of which the pseudocode is shown in the appendix
\subsection{MEDS Algorithms}
\label{sec:medsalgorithms}
In this section, we will give an algorithmic overview of the three algorithms of MEDS: key generation, signature generation, and signature verification. The complete and detailed pseudocode of these algorithms is shown in Appendix \ref{app:medsalgs}.

\subsubsection{Notations and Definitions}
\todo[inline]{List notations and definitions used in the MEDS algorithms}

\subsubsection{Key Generation}
The full key generation algorithm for MEDS is shown in Algorithm \ref{alg:medskeygen}.
\todo[inline]{Give a brief overview of the key generation algorithm.}

\subsubsection{Signature Generation}
The full signature generation algorithm for MEDS is shown in Algorithm \ref{alg:medssign}.
\todo[inline]{Give a brief overview of the signature generation algorithm.}

\subsubsection{Signature Verification}
The full signature verification algorithm for MEDS is shown in Algorithm \ref{alg:medsverify}.
\todo[inline]{Give a brief overview of the signature verification algorithm.}

\section{ARMv8 and NEON}
\label{sec:armv8}
\todo[inline]{Somewhere, explain cache poisoning and timing attacks}
\todo[inline]{Any meaningful citations in this section?}
\todo[inline]{Cite NEON reference manual maybe?}
\todo[inline]{Intrinsics page?}

In this thesis, we will focus on optimizing the MEDS implementation for the ARMv8 architecture. To this end, we will use a Raspberry Pi 4 Model B, which has a 64-bit quad-core ARM Cortex-A72 CPU. We will be testing and comparing the performance of the MEDS implementation on this device.

\subsection{ARMv8 Architecture}
ARMv8 is the architecture that is used in the ARM Cortex-A72 and a lot of other processors. The default instroctuion set for ARMv8 is AArch64, a 64-bit instruction set that has more registers and higher performance than the 32-bit AArch32 instruction set.

\subsection{Vectorization and SIMD}
Single Instruction, Multiple Data (SIMD) is a type of instruction that operates on multiple pieces of data in parallel. Using this technique, it is possible to execute a single operation (such as an addition or multiplication) on multiple numbers in a time that is similar to the conventional operation on a single number. This can greatly improve the performance of algorithms that lend themselves to parallelization.

In ARM, the SIMD instruction set is called NEON or Advanced SIMD (both terms refer to the same thing). NEON is a 128-bit SIMD architecture extension that is required in all standard ARMv8 implementations \cite{ARMv8A-ProgrammersGuide}. The NEON unit consists of 32 128-bit registers, each of which can be used to store 16 8-bit integers, 8 16-bit integers, 4 32-bit integers, or 2 64-bit integers. The NEON instruction set includes a wide range of instructions that can be used to perform operations on these registers.

\subsection{Assembly Instructions and Latency}
\todo[inline]{For NEON; add pipeline information and latency for used assembly instructions}

\section{Related Work}
\todo[inline]{Give Related Work}
\begin{itemize}
  \item The two GitHub repositories for the low-level and high-level optimizations of tradidional MEDS.
\end{itemize}
\todo[inline]{Add other post-quantum schemes that have been optimized on the same platform (ARMv8). Mostly signature schemes, but possibly also other ones. Definitely Keccak (with extended Keccak package).}

\chapter{Research Objectives}
\label{ch:researchobjectives}
\todo[inline]{Explain MEDS speedup goals}
\todo[inline]{Explain SIMD speedup}
\todo[inline]{Explain ARM speedup goals (IoT, mobile, etc.)}

\chapter{Profiling}
\label{ch:profiling}
\section{Profiling Techniques}
In order to obtain a better understanding of the performance of (specific functions of) MEDS, we need to profile the implementation. Profiling is the process of measuring the space or time complexity of a program or a specific function. The goal of profiling is to identify the bottlenecks in the speed or memory usage of a program, these are the parts of the program that take the most time or memory. Usually, we hope that a small part of the program is responsible for a large part of the time or memory usage, and that this part can be optimized to improve the overall performance.

Typically, profiling is done by running the program with a profiler, which is a tool that measures the space or time that is used by the program or a specific functions. There exist a wide variety of profilers for C, such as GProf \cite{graham1982gprof}, Valgrind \cite{nethercote2007valgrind}, and Linux-Perf \cite{de2010new}. In our case, the most accurate way to measure the performance is to measure the number of cycles that are used by the program or a specific function, which can be done with Linux-Perf.

\subsection{Cycle Counting}
Cycle counting is a technique that is used to measure the number of CPU cycles that it takes to execute a certain program or function. This is usually done by accessing the performance monitoring unit (PMU) of the CPU, which is a CPU component that measures the performance of the processor. Typically, these PMUs contain a register that can be read to obtain the number of cycles executed since a certain point in time. On Linux, it is very easy to access this data using the Linux-Perf tool \cite{de2010new}, which can be used to measure the number of instructions executed, number of cache misses, etc.

\subsubsection{Advantages}
The advantages of profiling the code using a cycle counter are:
\begin{itemize}
  \item \textbf{Exact}: Measuring the cycle counter results in the most exact measurement of time. For comparison, using a technique that measures the current time in (nano)seconds is less accurate, because the CPU is capable of executing multiple cycles in a single nanosecond.
  \item \textbf{Low Overhead}: Measuring the cycle counter has a very low additional performance overhead to the program, as it usually consists of reading a single register.
  \item \textbf{Precise}: By annotating the code with our own cycle counter, we can measure the performance of specific functions or even specific lines of code.
\end{itemize}

\subsubsection{Disadvantages}
The disadvantages of profiling the code using a cycle counter are:
\begin{itemize}
  \item \textbf{Interference}: The program to be measured shares the CPU (core) with other programs, which can interfere with measurements. If another program is switched in by the operating system, the cycle counter will also count the cycles that were used by this program. Although this usually doesn't have a big impact on profiling results, this can be problematic for obtaining accurate benchmarks.
  \item \textbf{Architecture}: The way in which the cycle counter is accessed is different for each architecture. However, since we use the perf tool, this is abstracted away for us.
\end{itemize}

\subsubsection{Problem Mitigation}
There are a few problems with cycle counting that we need to mitigate. First of all, there are a few features on modern CPUs that will cause this technique to produce inaccurate results. These features include frequency scaling (based on the current workload, a CPU can change its clock frequency to save power) and hyperthreading (multiple threads share the same CPU core). It is essential to disable these features to obtain accurate results.

Another problem is the problem of program interference (see above). Unfortunately, this is a problem that is hard to prevent completely, but we can work around it. By running the program multiple times and taking the median of the results, we can reduce the impact of interference on the results. This is a common technique in benchmarking.

\section{MEDS Profiling Results}
\label{sec:medsprofilingresults}

\subsection{Measurement Setup}
We added cycle count measurements to all MEDS functions that we anticipate will require a significant amount of time. We ran our profiling tests on a Raspberry Pi 4 Model B with a 64-bit quad-core ARM Cortex-A72 CPU clocked at 1.5 GHz. We decided to profile the code for the MEDS-55520 parameter set, which is in the middle of the three parameter sets in terms of security level. The results will be representative for the other parameter sets as well. We executed measurements for the three algorithms of a digital signature scheme: key generation, signing, and verification. The results are shown in Tables \ref{tab:medskeygenfunctions} (key generation), \ref{tab:medssigningfunctions} (signing), and \ref{tab:medsverificationfunctions} (verification). For each algorithm, we list the functions or code sections that take up more than 1\% of the total number of cycles. We provide the number of megacycles (MCycles) that were used in that function, the percentage of the total number of cycles that were used by that function, and the number of times that function was called. Note that the number of cycles cannot be divided by the number of calls to obtain the average number of cycles per call, because the number of cycles that are used by a function can depend on the input.

\begin{table}[]
  \centering
  \begin{tabular}{lrrr}
    \toprule
    \textbf{Function} & \textbf{\# MCycles} ($\pm$) & \textbf{\% of Total} ($\pm$) & \textbf{\# Calls} \\
    \midrule
      \texttt{pmod\_mat\_mul} & 15.97 & 69.81 & 70 \\
      \texttt{pmod\_mat\_syst} & 2.07 & 9.07 & 6 \\
      \texttt{rnd\_sys\_mat} & 2.07 & 9.06 & 1 \\
      \texttt{solve\_opt} & 1.41 & 6.18 & 3 \\
      \texttt{bs\_fill} & 1.06 & 4.64 & 2 \\
    \midrule
      Cumulative & 22.59 & 98.76 & \\
      Remaining & 0.28 & 1.24 & \\
    \bottomrule
  \end{tabular}
  \caption{MEDS-55520 Keygen Profiling Results}
  \label{tab:medskeygenfunctions}
\end{table}

\begin{table}[]
  \centering
  \begin{tabular}{lrrr}
    \toprule
    \textbf{Function} & \textbf{\# MCycles} ($\pm$) & \textbf{\% of Total} ($\pm$) & \textbf{\# Calls} \\
    \midrule
      \texttt{pmod\_mat\_mul} & 2523.80 & 69.22 & 14635 \\
      \texttt{pmod\_mat\_syst} & 391.87 & 10.75 & 1040 \\
      \texttt{solve\_opt} & 293.11 & 8.04 & 624 \\
      \texttt{bs\_fill} & 212.75 & 5.84 & 208 \\
      \texttt{shake256\_absorb} & 202.92 & 5.57 & 212 \\
    \midrule
      Cumulative & 3624.46 & 99.42 & \\
      Remaining & 21.14 & 0.58 & \\
    \bottomrule
  \end{tabular}
  \caption{MEDS-55520 Signing Profiling Results}
  \label{tab:medssigningfunctions}
\end{table}

\begin{table}[]
  \centering
  \begin{tabular}{lrrr}
    \toprule
    \textbf{Function} & \textbf{\# MCycles} ($\pm$) & \textbf{\% of Total} ($\pm$) & \textbf{\# Calls} \\
    \midrule
      \texttt{pmod\_mat\_mul} & 2525.93 & 69.23 & 14560 \\
      \texttt{pmod\_mat\_syst} & 391.58 & 10.73 & 1040 \\
      \texttt{solve\_opt} & 293.18 & 8.04 & 624 \\
      \texttt{bs\_fill} & 212.75 & 5.83 & 208 \\
      \texttt{shake256\_absorb} & 202.94 & 5.56 & 210 \\
    \midrule
      Cumulative & 3626.38 & 99.39 & \\
      Remaining & 22.26 & 0.61 & \\
    \bottomrule
  \end{tabular}
  \caption{MEDS-55520 Verification Profiling Results}
  \label{tab:medsverificationfunctions}
\end{table}

% \begin{tikzpicture}
%   \pie[
%     sum=100,
%     text=legend,
%     % pos={8,0},
%     % explode=0.1,
%     color={pie3,pie4,pie5,pie6,pie7,pie8,pie9}
%   ]{59.3/matmul, 17.1/matsyst, 6.1/shakeabsorb, 1.2/GFinv, 16.3/Other}
%   \pie[
%     sum=100,
%     color={pie3,pie4,pie5,pie6,pie7,pie8,pie9},
%     hide number
%   ]{59.3/,17.1/,6.1/,1.2/1.2\%}
%   \pie[
%     sum=100,
%     color={pie3,pie4,pie5,pie6,pie7,pie8,pie9}
%   ]{59.3/,17.1/,6.1/}
% \end{tikzpicture}

\subsection{Result Analysis}
Because of the way that MEDS works, the results of the signing and verification operations are very similar. For key generation, the results in the table account for 98.76\% of the total number of cycles. For signing and verification, this number is 99.42\% and 99.39\%, respectively. In all three algorithms, the remainder of the cycles is spent on a wide set of functions that take up a small amount of time. Given that there are only a few functions that take up a significant amount of time, we can conclude that the performance of MEDS is mostly determined by these functions.

\subsubsection{Matrix Multiplication}
For all three operations, the \texttt{pmod\_mat\_mul} function takes up the most time, almost 70\%. This function is used to multiply two matrices $A^{m \times n}$ and $B^{n \times o}$ over a finite field $\mathbb{F}_q$. The function is implemented in MEDS using a naive algorithm that computes the dot product of each row of $A$ with each column of $B$, followed by a reduction modulo $q$. The time complexity of this algorithm is $\mathcal{O}(mno)$ ($= \mathcal{O}(n^3)$ for square matrices).
% This is so much time that I was not able to finish this thesis. Mic drop; I am a failure. <- van fringerlie

\subsubsection{Matrix Systemization}
The \texttt{pmod\_mat\_syst} function (\texttt{pmod\_mat\_syst\_ct\_partial\_swap\_backsub} in the code, but shortened for readability) is responsible for about 11\% of the total number of cycles for signing and verification. This function is used to systemize a matrix $A^{m \times n}$ over a finite field $\mathbb{F}_q$. This is done using a Gaussian elimination algorithm that operates in constant time, meaning the code will always take the same amount of time to execute for matrices with the same dimensions.

\todo[inline]{Perform complexity analysis?}

\subsubsection{System Solving}
The \texttt{solve\_opt} function is responsible for about 8\% of the total number of cycles for signing and verification. This function is used to solve a system of linear equations over a finite field $\mathbb{F}_q$. In MEDS, the systems that need to be solved are constructed in a very specific way, which allows for a more efficient method of solving them (as opposed to using a more general algorithm like Gaussian elimination). Even though the system solving algorithm is thus optimized, it still takes up a significant amount of time.

\subsubsection{Bitstream Filling}
The \texttt{bs\_fill} section is responsible for about 6\% of the total number of cycles for signing and verification. In this section of the code, multiple calls are made to the \texttt{bs\_init}, \texttt{bs\_write}, and \texttt{bs\_finalize}. We decided to group them together because they are all part of the same operation: filling a bitstream with elements of the finite field $\mathbb{F}_q$. In the MEDS parameter sets that we use, the finite field is $\mathbb{F}_{4093}$, which means that the bitstream is filled with 12-bit elements. This is done to make the resulting keys and signatures more compact.

\subsubsection{SHAKE256}
\label{sec:shake256}
A small percentage of the total number of cycles in each of the three operations is used by either \texttt{shake256\_squeeze} or \texttt{shake256\_absorb}. Shake256 is a cryptographic hash function that can be used as an extendable output function (XOF). It is part of the SHA-3 family \cite{dworkin2015sha} and is based on the Keccak sponge construction \cite{bertoni2013keccak}. MEDS uses SHAKE256 to generate random field elements and to hash the challenge strings that are used in the Fiat-Shamir transform (see Section \ref{sec:medsworks}).

\subsubsection{Random Systemized Matrix Generator}
The \texttt{rnd\_sys\_mat} function is responsible for about 9\% of the total number of cycles for key generation. This function is used to generate a random systemized matrix over a finite field $\mathbb{F}_q$. Nearly all of its cycles are spent on generating random field elements using the \texttt{shake256\_squeeze} function (see Section \ref{sec:shake256}).

\chapter{Methodology}
\label{ch:methodology}
We have established two approaches to optimize the MEDS implementation. These approaches are not specific to ARMv8, but their implementation will be tailored to the ARMv8 architecture.
\begin{itemize}
  \item \textbf{Low-Level Optimization}:\\
  This approach focuses on optimizing the MEDS implementation at a low level. This means that we will look at individual functions (such as matrix multiplication and matrix systemization) that take up a significant amount of time and optimize them. The input and output of these functions are thus not changed, but the way in which the result is computed is optimized using techniques such as vectorization.
  \item \textbf{High-Level Optimization}:\\
  This approach focuses on optimizing the MEDS implementation at a high level. The Fiat-Shamir transform used in MEDS (see Section \ref{sec:fiatshamir}) uses $t$ challenges to increase the security of the scheme. The values of $t$ for each parameter set are displayed in Table \ref{tab:medsparametersets} (Section \ref{sec:parametersets}). As can be seen from the algorithmic overviews in Section \ref{sec:medsalgorithms}, the computation of each challenge is done in the exact same way. This means that we can compute multiple challenges in parallel, which can greatly increase the performance of the scheme. As opposed to low-level optimization, this approach changes the input and output of the underlying functions to take in and return the inputs and outputs of multiple challenges at once.
\end{itemize}
In this Chapter, we will start by discussing how we will implement modular reduction, an operation that is the same for both approaches (Section \ref{sec:modularreduction}). We will then discuss the implementation of the two approaches in Sections \ref{sec:lowleveloptimization} and \ref{sec:highleveloptimization}, respectively. Lastly, we will provide an optional optimization technique to the way in which hash functions are used in MEDS in Section \ref{sec:hashfunctionoptimization}. This optimization can be applied to both approaches, but it changes the underlying MEDS algorithm, causing the resulting signatures to be different.

\section{Modular Reduction}
\label{sec:modularreduction}
Throughout the entirety of the MEDS implementation, modular reduction is used extensively to reduce the size of the elements so they fit in the finite field $\mathbb{F}_q$. The finite field that is used in MEDS for the parameter sets that we consider is $\mathbb{F}_{4093}$, which means that all elements are reduced modulo 4093. In the reference implementation of MEDS, all modulo operations are done using the \texttt{\%} operator in C. As we will use NEON assembly instructions and C intrinsics to optimize the MEDS implementation, we can not rely on this operator, as it is not defined for NEON registers and there is no direct alternative in assembly.

Because of this, we will need to implement our own modular reduction function that can be used with NEON registers. It is essential that this function is as fast as possible, as it is used in many places in the MEDS implementation. There are various algorithms that can be used to perform modular reduction. Especially for large moduli, there are a lot of possible algorithms and optimizations to choose from\todo{Cite?}. However, as our modulus is relatively small and fits in just 12 bits, we do not have to consider these more complex algorithms. Instead, we have considered the following well-known algorithms.
\begin{itemize}
  \item \textbf{Naive Reduction}\\
  The naive reduction algorithm is slow and not suitable for our purposes, but we will use it as a baseline to compare the other algorithms to. This algorithm works by applying an integer division instruction to the input, followed by a multiplication with the modulus and a subtraction. The main problem with this approach is that division is not a constant time operation, which can lead to timing attacks. Furthermore, the division operation is usually relatively slow compared to other operations.
  \todo[inline]{References to timing attack section?}
  \item \textbf{Montgomery Reduction}\\
  Montgomery reduction is a modular reduction algorithm that is based on the Montgomery multiplication algorithm. It does not use a division instruction, which makes it suitable for constant time operations. Instead, it works by subtracting a multiple of the modulus from the input such that the input is (almost) smaller than the modulus. The algorithm requires the input to be converted to a Montgomery representation, after which (for our input sizes) the reduction algorithm can be executed with 2 multiplications, 2 additions/subtractions, and a right shift, followed by a conditional subtraction.
  \todo[inline]{Cite}
  \item \textbf{Barrett Reduction}\\
  Barrett reduction is a modular reduction algorithm that is similar to Montgomery reduction in the sense that it also subtracts a multiple of the modulus from the input. However, it does not require the input to be converted to a different representation. For our input sizes, the algorithm can be executed with 2 multiplications, 1 subtraction, and a right shift (with an optional conditional subtraction, see Section \ref{sec:barrettreduction}).
  \todo[inline]{Cite}
\end{itemize}

Montgomery reduction is generally very efficient when a large chain of multiplications is required and the overhead of converting to and from Montgomery representation is negligible compared to the number of multiplications/reductions. Although the structure of MEDS does allow us to convert the entire input to Montgomery representation and perform all multiplications in this representation, we have decided to use Barrett reduction instead, as the number of instructions required for the reduction of a single element is lower than for Montgomery reduction.

\subsection{Barrett Reduction}
\label{sec:barrettreduction}
Barrett reduction works by approximating the modular reduction. Given an unsigned integer $a$ and a modulus $n$, clearly
\[
  a \mod n = a - \left\lfloor \frac{a}{n} \right\rfloor \cdot n.
\]

From this, the Barrett reduction formula for unsigned integers can be derived (Definition \ref{def:barrettreduction}).

\begin{definition}[Barrett Reduction for unsigned integers]
  \label{def:barrettreduction}
  Let $a$ be an unsigned integer and $n$ be a modulus.
  Let $R$ be a constant such that $R = 2^k > n$ for some $k$.
  \[
    a \mod n = a - \left\lfloor \frac{a \cdot \left[\frac{R}{n}\right]}{R} \right\rfloor \cdot n.
  \]
  where $\left[\right]$ represents a rounding operation such as floor or ceiling.
\end{definition}

As $R$ is a power of 2, the division by $R$ can be implemented as a cheap right shift operation. Additionally, the value of $m = \left[\frac{R}{n}\right]$ can be precomputed because the modulus $n$ is a constant. This leaves us with two things to choose: the value of $k$ and the rounding operation.

\subsubsection{Choice of $k$}
Usually, the value of $k$ chosen for Barrett reduction is as small as possible such that $2^k > n$. Combined with setting the rounding function of the precomputed value to the floor function, this results in a reduction that reduces to a value between $0$ and $2n-1$, requiring an additional conditional subtraction at the end of the reduction. Choosing a larger value of $k$ has one major disadvantage: the precomputed value $m = \left[\frac{R}{n}\right]$ becomes larger, which means that the multiplication $a \cdot m$ will result in a larger value (possibly leading to an overflow). However, choosing a larger value of $k$ also has a big advantage: the quotient $m$ will be closer to the actual value of $\frac{R}{n}$, which means that the reduction will be more accurate. If we know that the input $a$ will never be larger than a particular value, we can choose $k$ such that the conditional subtraction at the end of the reduction is not required. For this to work, we need to use the ceiling function for the rounding operation.

For our MEDS parameter sets, we know that all field elements fit into 12 bits. This means that any multiplication of two field elements will result in a value that fits into 24 bits. The largest possible value that any value can become (before reduction) results from the matrix multiplication algorithm, see Section \ref{sec:matrixmultiplication}. In this algorithm, the temporary value can (for parameter set MEDS-122000) become as large as $\log_2(k \cdot q \cdot q) = \log_2(44 \cdot 4093 \cdot 4093) \approx 29.5$ bits. This means that we need to pick a $k$ such that for all $0 \leq a < 2^{30}$, the reduction will not require a conditional subtraction.

As $2^{30}$ is a relatively small number, we use a brute force approach to find the smallest $k$ that satisfies this condition. This value turns out to be $k = 43$. This gives $m = \lceil \frac{2^{43}}{4093} \rceil = 0\text{x}80180481$. This number fits nicely into 32 bits, which means that we can store it in 32-bit NEON lanes.

\subsection{Implementation}
The reference code for our Barrett reduction algorithm is shown in Algorithm \ref{alg:barrettreduction}. This algorithm does not operate on vectorized data and serves as a baseline for implementing the NEON version.

\begin{algorithm}
  \caption{MEDS Barrett Reduction}
  \label{alg:barrettreduction}
  \begin{algorithmic}
    \Function{reduce}{$a$}
      \State $m \gets 0\text{x}80180481$
      \State $v \gets a \cdot m$
      \State $v \gets v \gg 43$
      \State \Return $a - v \cdot 4093$
    \EndFunction
  \end{algorithmic}
\end{algorithm}

The NEON version of the Barrett reduction algorithm is shown in Algorithm \ref{alg:neonbarretreductionc} (C code) and Algorithm \ref{alg:neonbarretreductionasm} (assembly code). The C code uses NEON intrinsics to perform the reduction on 128-bit NEON registers. The assembly code is a direct translation of the C code to ARMv8 assembly. Both algorithms assume that the input consists of four 32-bit unsigned integers that are stored in 4 lanes of a 128-bit NEON register. The output can either be stored in 4 32-bit lanes or 4 16-bit lanes, depending on the requirements of the calling function.

\begin{algorithm}
  \caption{NEON Barrett Reduction (C)}
  \label{alg:neonbarretreductionc}
  \lstinputlisting[language=C, style=CStyle]{code/barrett_reduce_c.c}
\end{algorithm}

\begin{algorithm}
  \caption{NEON Barrett Reduction (Assembly)}
  \label{alg:neonbarretreductionasm}
  \lstinputlisting[language={[x86masm]Assembler}, style=ASMStyle]{code/barrett_reduce_asm.s}
\end{algorithm}

From the assembly code, we can see that the reduction is done using 5 instructions (not counting the optional shrink). Including latency, the reduction takes 16 cycles to complete\todo{Check this, give reasoning} and is able to reduce 4 elements.

\section{Low-Level Optimization}
\label{sec:lowleveloptimization}
\todo[inline]{For every optimized function, give a minimum cycle bound and a reasoning. Explain the techniques used to optimize the functions.}
The low-level optimization approach focuses on optimizing the individual functions that take up a significant amount of time in the MEDS implementation. As can be seen from the profiling results displayed in Section \ref{sec:medsprofilingresults}, over 99\% of the total number of cycles used in signing and verification is used on just 5 functions. In this section, we will discuss the optimization of each of these functions.

\subsection{Matrix Multiplication}
\label{sec:matrixmultiplication}
Matrix multiplication is by far the most time-consuming function in MEDS, taking up almost 70\% of the total number of cycles in key generation, signing, and verification. The function is responsible for the simple task of multiplying two matrices $A^{m \times n}$ and $B^{n \times o}$ over the finite field $\mathbb{F}_{4093}$. Matrix multiplication is implemented using a naive algorithm that works by calculating the dot product of each row of $A$ with each column of $B$, followed by a reduction modulo 4093. The time complexity of this algorithm is $\mathcal{O}(mno)$. Algorithms have been discovered that can multiply two matrices in a lower time complexity, such as the Strassen algorithm\todo{cite} and the Coppersmith-Winograd algorithm\todo{cite}. However, these algorithms have such a high constant factor that they are not suitable for our purposes. Instead, we will optimize the naive algorithm using vectorization.

\subsection{Matrix Systemization}
\label{sec:matrixsystemization}

\subsection{System Solving}
\label{sec:systemsolving}

\subsection{Bitstream Filling}
\label{sec:bitstreamfilling}

\subsection{SHAKE256}
\label{sec:shake256lowlevel}

\section{High-Level Optimization}
\label{sec:highleveloptimization}
\todo[inline]{Explain how we perform the optimization on a high level, i.e. parallelize over the challenges}

\section{Hash Function Optimization}
\label{sec:hashfunctionoptimization}

\chapter{Results}
\label{ch:results}
\todo[inline]{Contains the results of the benchmarking of the non-optimized and optimized MEDS implementations.}

\chapter{Discussion}
\label{ch:discussion}
\todo[inline]{Discuss the results.}

\chapter{Future work}
\label{ch:futurework}
\todo[inline]{Discuss future work.}
- Use non-constant time implementations for various functions in the verification phase (both high and low level):
  * Gaussian elimination 0 checks
  * GF\_inv: use a lookup table
- Optimize shake256? See \url{https://eprint.iacr.org/2022/1243} and \url{https://github.com/cothan/NEON-SHA3\_2x}
  * Requires a change to MEDS, but this is not a problem
  * https://kannwischer.eu/papers/202\_armv8keccak.pdf
  * Cite keccak extended code package as well (Armv7)
  * https://gitlab.com/arm-research/security/pqax
  * Better KECCAK primitives possible on Armv8.2-A (Cortex-A72 uses Armv8-A). See: https://developer.arm.com/documentation/100076/0100/A64-Instruction-Set-Reference/A64-Cryptographic-Algorithms/A64-Cryptographic-instructions?lang=en
- Perform high-level optimizations for keygen
- Analyze minimum time complexity of low-level systemizer
- ARM Calling Convention PDF: https://github.com/ARM-software/abi-aa/releases (cite?)
- Change modular reduction to Barrett reduction (?)
- Adust the 2 python generation files with an abstract file for clearity
- Add explanation why high level slower -> data does not fit in cache. Check with toy parameter set.

\chapter{Conclusion}
\label{ch:conclusion}
\todo[inline]{Conclude the thesis.}

\bibliographystyle{plain}
\bibliography{bibliofile}

\input{appendix}

\end{document}